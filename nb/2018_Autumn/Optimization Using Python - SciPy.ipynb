{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Optimization Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture / tutorial, we will learn how to solve some simple optimization problems using Python. This involves a brief introduction to the various optimization libraries available, such as ```scipy.optimize```, ```ortools```, and ```cplex```. We will solve an example optimization problem using each library.\n",
    "\n",
    "***\n",
    "\n",
    "## Learning goals\n",
    "- Obtain an overview of optimization problems that can be easily solved using Python.\n",
    "- Know about some of the popular optimization libraries which have easy to use Python interfaces.\n",
    "- Learn the syntax to solve some simple optimization problems using at least a couple of the libraries discussed in this tutorial.\n",
    "- Test your understanding by solving a few of the practice problems in each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Prerequisites for running this notebook\n",
    "\n",
    "You should have Python 3.6 installed on your computer, with all necessary packages installed.\n",
    "\n",
    "We recommend that you install Anaconda (Python 3.6 version) from the following links depending on your OS:\n",
    "- For Windows: https://www.anaconda.com/download/#windows\n",
    "- For macOS: https://www.anaconda.com/download/#macos\n",
    "- For Linux: https://www.anaconda.com/download/#linux\n",
    "\n",
    "**If you are not using Anaconda, it is your responsibility to make sure that Python and all necessary packages are correctly installed and configured to be able to run this notebook.**\n",
    "\n",
    "***\n",
    "\n",
    "Once Anaconda is installed, open a **Terminal** (if you are using macOS / Linux), or **Anaconda Prompt** (if you are using Windows), and then create a new Python environment called **cme193**, by running the following command:<br>\n",
    "> ```conda create -n cme193 python=3.6```\n",
    "\n",
    "Next, change to the newly created virtual environment by running the command:\n",
    "\n",
    "On Windows\n",
    "> ```activate cme193``` <br>\n",
    "\n",
    "On macOS or Linux\n",
    "> ```source activate cme193```\n",
    "\n",
    "Next install all the necessary packages by running the following commands:\n",
    "\n",
    "> ```conda install nb_conda``` <br>\n",
    "> ```conda install -c anaconda scipy``` <br>\n",
    "> ```conda install -c conda-forge matplotlib``` <br>\n",
    "\n",
    "Now navigate to the directory containing this .ipynb file, from inside the terminal, and start jupyter notebook by typing the following command:\n",
    "> ```jupyter notebook```\n",
    "\n",
    "You should now be able to launch the .ipynb file from the browser. For more information on jupyter notebooks, read the <a href=\"https://jupyter-notebook.readthedocs.io/en/stable/notebook.html\" style=\"text-decoration: none;\">user documentation</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Introduction to scipy.optimize\n",
    "\n",
    "In this section we will learn how to solve some simple optimization problems using ```scipy```. The ```scipy.optimize``` package already gives us a lot of basic tools to solve a wide variety of important optimization problems. For more information please read the <a href=\"https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html\" style=\"text-decoration: none;\">documentation</a>.\n",
    "\n",
    "We can import the module as follows (henceforth to be referred to as ```sciopt```). We also import some other modules we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sciopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Solving a linear program\n",
    "\n",
    "The first example we will look at is that of solving a **linear program (LP)**. A linear program is any optimization problem of the following form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & c^{T}x  \\\\\n",
    "\\text{subject to} \\;\\; & A_{ub}x \\leq b_{ub} \\\\\n",
    "& A_{eq}x = b_{eq}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $c, x \\in \\mathbb{R}^n$, $A_{ub} \\in \\mathbb{R}^{m \\times n}$, $A_{eq} \\in \\mathbb{R}^{p \\times n}$, $b_{ub} \\in \\mathbb{R}^{m}$, and $b_{eq} \\in \\mathbb{R}^{p}$. It should be noted that all LP can be put in this form.\n",
    "\n",
    "```scipy.optimize``` provides a simple function ```scipy.optimize.linprog``` to solve such problems, which is documented <a href=\"https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.linprog.html#scipy.optimize.linprog\" style=\"text-decoration: none;\">here</a>. Currently, the only available algorithm that is implemented are the **simplex method**, and the **interior point method**. We will demonstrate its usage using a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 1\n",
    "Let us consider the problem\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & x_1 + 2 x_2  \\\\\n",
    "\\text{subject to} \\;\\; & x_1 \\leq 1 \\\\\n",
    "& 5 x_1 + x_2 \\geq 0\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In order to solve it, we first need to transform it to the form that ```scipy.optimize.linprog``` requires. The problem is clearly equivalent to\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & x_1 + 2 x_2  \\\\\n",
    "\\text{subject to} \\;\\; & x_1 \\leq 1 \\\\\n",
    "& -5 x_1 - x_2 \\leq 0\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The following Python code then solves this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define problem parameters\n",
    "c = [1, 2]\n",
    "A_ub = [[1, 0], [-5, -1]]\n",
    "b_ub = [1, 0]\n",
    "bounds = ((None, None), (None, None))\n",
    "\n",
    "# Solve the LP\n",
    "result = sciopt.linprog(c=c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: -9.000000000000004\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 2\n",
      "   slack: array([0., 0.])\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 1., -5.])\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Notice that we must explicitly set the ```bounds``` parameter in the above problem. If we don't pass this parameter, the default assumption is that the variables are non-negative.\n",
    "\n",
    "You can additionally pass the parameter ```options={\"disp\": True}``` to print convergence messages from the solver. **Solver method specific parameters can also be passed as optional parameters in** ```options```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -9.000000   \n",
      "         Iterations: 2\n"
     ]
    }
   ],
   "source": [
    "# Solve the LP and print convergence messages\n",
    "result = sciopt.linprog(c=c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, options={\"disp\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution: x1 =  1.0 , x2 =  -5.000000000000002\n",
      "Optimal value =  -9.000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Extract the solution and print it\n",
    "obj_optimal = result['fun']\n",
    "x = result['x']\n",
    "print(\"Optimal solution: x1 = \", x[0], \", x2 = \", x[1])\n",
    "print(\"Optimal value = \", obj_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 2\n",
    "Let us change the problem by adding an equality constraint\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & x_1 + 2 x_2  \\\\\n",
    "\\text{subject to} \\;\\; & x_1 \\leq 1 \\\\\n",
    "& 5 x_1 + x_2 \\geq 0 \\\\\n",
    "& x_1 + x_2 = 3.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In order to solve it, we first need to transform it to the form that ```scipy.optimize.linprog``` requires. The problem is clearly equivalent to\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & x_1 + 2 x_2  \\\\\n",
    "\\text{subject to} \\;\\; & x_1 \\leq 1 \\\\\n",
    "& -5 x_1 - x_2 \\leq 0 \\\\\n",
    "& x_1 + x_2 = 3.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The following Python code then solves this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the LP\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 5.000000    \n",
      "         Iterations: 2\n",
      "\n",
      "\n",
      "Optimal solution: x1 =  1.0 , x2 =  2.0\n",
      "Optimal value =  5.0\n"
     ]
    }
   ],
   "source": [
    "# Define problem parameters\n",
    "c = [1, 2]\n",
    "A_ub = [[1, 0], [-5, -1]]\n",
    "b_ub = [1, 0]\n",
    "A_eq = [[1, 1]]\n",
    "b_eq = [3]\n",
    "bounds = ((None, None), (None, None))\n",
    "\n",
    "# Solve the LP\n",
    "print(\"Solving the LP\")\n",
    "result = sciopt.linprog(c=c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, options={\"disp\": True})\n",
    "\n",
    "# Extract the solution and print it\n",
    "obj_optimal = result['fun']\n",
    "x = result['x']\n",
    "print(\"\\n\")\n",
    "print(\"Optimal solution: x1 = \", x[0], \", x2 = \", x[1])\n",
    "print(\"Optimal value = \", obj_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternate way of solving the problem\n",
    "Notice that the inequality constraint ```x1 <= 1``` is a **bound constraint**. Hence, an alternate way to solve **Example 2** is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the LP\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 5.000000    \n",
      "         Iterations: 2\n",
      "\n",
      "\n",
      "Optimal solution: x1 =  1.0 , x2 =  2.0\n",
      "Optimal value =  5.0\n"
     ]
    }
   ],
   "source": [
    "# Define problem parameters\n",
    "c = [1, 2]\n",
    "A_ub = [[-5, -1]]\n",
    "b_ub = [0]\n",
    "A_eq = [[1, 1]]\n",
    "b_eq = [3]\n",
    "bounds = ((None, 1), (None, None))\n",
    "\n",
    "# Solve the LP\n",
    "print(\"Solving the LP\")\n",
    "result = sciopt.linprog(c=c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, options={\"disp\": True})\n",
    "\n",
    "# Extract the solution and print it\n",
    "obj_optimal = result['fun']\n",
    "x = result['x']\n",
    "print(\"\\n\")\n",
    "print(\"Optimal solution: x1 = \", x[0], \", x2 = \", x[1])\n",
    "print(\"Optimal value = \", obj_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 3\n",
    "Some special problems can be reduced to a LP. Consider the following optimization problem\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & x_1 + 2 x_2 - 3 x_3  \\\\\n",
    "\\text{subject to} \\;\\; & |x_1| \\leq 1 \\\\\n",
    "& |x_2| \\leq 2 \\\\\n",
    "& |x_3| \\leq 1 \\\\\n",
    "& x_1 + x_2 + x_3 = 1.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "But this is just equivalent to\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & x_1 + 2 x_2 - 3 x_3  \\\\\n",
    "\\text{subject to} \\;\\; & -1 \\leq x_1 \\leq 1 \\\\\n",
    "& -2 \\leq x_2 \\leq 2 \\\\\n",
    "& -1 \\leq x_3 \\leq 1 \\\\\n",
    "& x_1 + x_2 + x_3 = 1.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The following Python code then solves this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the LP\n",
      "Primal Feasibility  Dual Feasibility    Duality Gap         Step             Path Parameter      Objective          \n",
      "1.0                 1.0                 1.0                 -                1.0                 -2.0                \n",
      "0.2580267693811     0.2580267693811     0.2580267693811     0.7472714508774  0.2580267693811     -4.874990060633     \n",
      "0.02400575024644    0.02400575024644    0.02400575024644    0.9172681112386  0.02400575024644    -3.930935041508     \n",
      "0.0001908759146977  0.0001908759145871  0.0001908759145884  0.9958556392802  0.0001908759146894  -4.001229925194     \n",
      "9.555359004043e-09  9.555359095733e-09  9.555358282398e-09  0.9999499421812  9.555358866709e-09  -4.000000061479     \n",
      "4.773407186698e-13  4.778634535547e-13  4.776179451937e-13  0.9999499968491  4.777679471601e-13  -4.000000000003     \n",
      "Optimization terminated successfully.\n",
      "\n",
      "\n",
      "Optimal solution: x1 =  0.9999999999999634 , x2 =  -1.0000000000018114 , x3 =  0.9999999999998039\n",
      "Optimal value =  -4.000000000003071\n"
     ]
    }
   ],
   "source": [
    "# Define problem parameters\n",
    "c = [1, 2, -3]\n",
    "A_eq = [[1, 1, 1]]\n",
    "b_eq = [1]\n",
    "bounds = ((-1, 1), (-2, 2), (-1, 1))\n",
    "\n",
    "# Solve the LP\n",
    "print(\"Solving the LP\")\n",
    "result = sciopt.linprog(c=c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"interior-point\", options={\"disp\": True})\n",
    "\n",
    "# Extract the solution and print it\n",
    "obj_optimal = result['fun']\n",
    "x = result['x']\n",
    "print(\"\\n\")\n",
    "print(\"Optimal solution: x1 = \", x[0], \", x2 = \", x[1], \", x3 = \", x[2])\n",
    "print(\"Optimal value = \", obj_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 4\n",
    "Here is another interesting example. Consider the following optimization problem\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & \\max \\{|x_1|, |x_2|, |x_3|\\}  \\\\\n",
    "\\text{subject to} \\;\\; & x_1 + x_2 + x_3 \\geq 1.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "It is easy to show that this problem is equivalent to the problem (this is called the **epigraph form** of the problem)\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & s  \\\\\n",
    "\\text{subject to} \\;\\; & |x_1| \\leq s \\\\\n",
    "& |x_2| \\leq s \\\\\n",
    "& |x_3| \\leq s \\\\\n",
    "& s \\geq 0 \\\\\n",
    "& x_1 + x_2 + x_3 \\geq 1\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the minimization is now over the variables $x_1, x_2, x_3,$ and $s$.\n",
    "\n",
    "As before we need to change this problem into a form that is suitable for ```scipy.optimize.linprog```. The problem can be written equivalently as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & s  \\\\\n",
    "\\text{subject to} \\;\\; & x_1 - s \\leq 0 \\\\\n",
    "& x_2 - s \\leq 0 \\\\\n",
    "& x_3 - s \\leq 0 \\\\\n",
    "& - x_1 - s \\leq 0 \\\\\n",
    "& - x_2 - s \\leq 0 \\\\\n",
    "& - x_3 - s \\leq 0 \\\\\n",
    "& - x_1 - x_2 - x_3 \\leq -1 \\\\\n",
    "& s \\geq 0 .\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The following Python code then solves this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the LP\n",
      "Primal Feasibility  Dual Feasibility    Duality Gap         Step             Path Parameter      Objective          \n",
      "1.0                 1.0                 1.0                 -                1.0                 1.0                 \n",
      "0.1929160231033     0.1929160231033     0.1929160231033     0.8097074289665  0.1929160231033     0.7308257137377     \n",
      "0.006450902537359   0.006450902537359   0.006450902537359   0.9797701682345  0.006450902537359   0.3336302680012     \n",
      "3.775130950068e-07  3.775130944228e-07  3.775130943962e-07  0.9999416764449  3.775130944919e-07  0.3333334186219     \n",
      "1.887590085209e-11  1.887565983396e-11  1.887567879777e-11  0.9999499999434  1.887566346212e-11  0.3333333333376     \n",
      "Optimization terminated successfully.\n",
      "\n",
      "\n",
      "Optimal solution: x1 =  0.3333333333374885 , x2 =  0.33333333333748894 , x3 =  0.3333333333374887 , s =  0.3333333333375978\n",
      "Optimal value =  0.3333333333375978\n"
     ]
    }
   ],
   "source": [
    "# Define problem parameters\n",
    "c = [0, 0, 0, 1]\n",
    "A_ub = [[1, 0, 0, -1], [0, 1, 0, -1], [0, 0, 1, -1], [-1, 0, 0, -1], [0, -1, 0, -1], [0, 0, -1, -1], [-1, -1, -1, 0]]\n",
    "b_ub = [0, 0, 0, 0, 0, 0, -1]\n",
    "bounds = ((None, None), (None, None),(None, None), (0, None))\n",
    "\n",
    "# Solve the LP\n",
    "print(\"Solving the LP\")\n",
    "result = sciopt.linprog(c=c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"interior-point\", options={\"disp\": True})\n",
    "\n",
    "# Extract the solution and print it\n",
    "obj_optimal = result['fun']\n",
    "x = result['x']\n",
    "print(\"\\n\")\n",
    "print(\"Optimal solution: x1 = \", x[0], \", x2 = \", x[1], \", x3 = \", x[2], \", s = \", x[3])\n",
    "print(\"Optimal value = \", obj_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 1\n",
    "Compare the efficiency of the **simplex method** and the **interior point method** at solving linear programs, by generating some random LPs, and then solving them using both options. Plot the timing results as a function of problem size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Minimum weight matching in bipartite graphs\n",
    "\n",
    "Given an (undirected) **complete bipartite graph** $G = (V_1, V_2, E)$, with an edge cost function $C : E \\rightarrow \\mathbb{R}$, the goal is to find a minimum weight **matching** $M \\subset E$ that covers the smaller of the two sets $V_1$ or $V_2$. Thus $V_1$ and $V_2$ need not be of the same sizes. $G$ being complete bipartite graph means that there is an edge $e \\in E$ between every pair of vertices $v_1 \\in V_1$, and $v_2 \\in V_2$. A matching refers to a selection of edges such that no vertex is covered more than once. This problem is also known as the **linear sum assignment** problem.\n",
    "\n",
    "Let $|V_1| = N_1$, and $|V_2| = N_2$, and without loss of generality assume that $N_1 \\leq N_2$. If we index the vertices in $V_1$ by $i$, and those in $V_2$ by $j$, then $e_{ij}$ will refer to the edge between $i$ and $j$, and similarly $C_{ij}$ will refer to the cost of the edge $e_{ij}$. Let $X_{ij}$ be a boolean $\\{0,1\\}$ variable that indicates whether edge $e_{ij}$ is selected or not. Then our goals can be represented by the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{minimize} \\;\\; & \\sum_{i=1}^{N_1} \\sum_{j=1}^{N_2} C_{ij} X_{ij}  \\\\\n",
    "\\text{subject to} \\;\\; & X_{ij} \\in \\{0, 1\\}, \\;\\; \\forall \\;\\; i, j \\\\\n",
    "& \\sum_{j=1}^{N_2} X_{ij} = 1, \\;\\; \\forall \\;\\; i \\\\\n",
    "& \\sum_{i=1}^{N_1} X_{ij} \\leq 1, \\;\\; \\forall \\;\\; j.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "```scipy.optimize``` provides an inbuilt function ```scipy.optimize.linear_sum_assignment``` that solves exactly this problem, which is documented <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html#scipy.optimize.linear_sum_assignment\" style=\"text-decoration: none;\">here</a>. The algorithm used to solve this problem is the famous **Hungarian algorithm**, also known as the **Kuhn-Munkres algorithm**, although it was discovered in 2006 that <a href=\"https://en.wikipedia.org/wiki/Carl_Gustav_Jacob_Jacobi\" style=\"text-decoration: none;\">Carl Gustav Jacobi</a> had solved the problem in 1840s (published only posthumously in 1890)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let us see an example.\n",
    "\n",
    "### Example 1\n",
    "Consider the following $C$ matrix\n",
    "\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "2 & 1 & -1 & 1 \\\\\n",
    "4 & 5 & -2 & -3 \\\\\n",
    "1 & 2 & -1 & 5 \\\\\n",
    "-2 & 3 & 4 & 0\n",
    "\\end{bmatrix}\n",
    "\\;\\;.\n",
    "$$\n",
    "\n",
    "This problem is easily solved using the following Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the linear sum assignment problem\n",
      "\n",
      "\n",
      "Row index :  [0 1 2 3]\n",
      "Col index :  [1 3 2 0]\n",
      "\n",
      "\n",
      "The selected edges in the optimal assignment and their costs are:\n",
      "Edge (0,1) , Cost = 1\n",
      "Edge (1,3) , Cost = -3\n",
      "Edge (2,2) , Cost = -1\n",
      "Edge (3,0) , Cost = -2\n",
      "\n",
      "\n",
      "The optimal cost is :  -5\n"
     ]
    }
   ],
   "source": [
    "# Define problem parameters\n",
    "cost_matrix = [[2, 1, -1, 1], [4, 5, -2, -3], [1, 2, -1, 5], [-2, 3, 4, 0]]\n",
    "\n",
    "# Solve the linear sum assignment problem\n",
    "print(\"Solving the linear sum assignment problem\")\n",
    "row_ind, col_ind = sciopt.linear_sum_assignment(cost_matrix=cost_matrix)\n",
    "\n",
    "# Print the solution\n",
    "print(\"\\n\")\n",
    "print(\"Row index : \", row_ind)\n",
    "print(\"Col index : \", col_ind)\n",
    "\n",
    "# Print selected edges and the costs\n",
    "print(\"\\n\")\n",
    "print(\"The selected edges in the optimal assignment and their costs are:\")\n",
    "cost_opt = 0\n",
    "for ind, row in enumerate(row_ind):\n",
    "    col = col_ind[ind]\n",
    "    cost_opt += cost_matrix[row][col]\n",
    "    print(\"Edge (\" + str(row) + \",\" + str(col) + \") , Cost = \" + str(cost_matrix[row][col]))\n",
    "\n",
    "# Print optimal cost\n",
    "print(\"\\n\")\n",
    "print(\"The optimal cost is : \", cost_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 2\n",
    "\n",
    "Consider the following $C$ matrix\n",
    "\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "2 & 1 & -1 & 1 \\\\\n",
    "4 & 5 & -2 & -3 \\\\\n",
    "1 & 2 & -1 & 5\n",
    "\\end{bmatrix}\n",
    "\\;\\;.\n",
    "$$\n",
    "\n",
    "This problem is easily solved using the following Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the linear sum assignment problem\n",
      "\n",
      "\n",
      "Row index :  [0 1 2]\n",
      "Col index :  [2 3 0]\n",
      "\n",
      "\n",
      "The selected edges in the optimal assignment and their costs are:\n",
      "Edge (0,2) , Cost = -1\n",
      "Edge (1,3) , Cost = -3\n",
      "Edge (2,0) , Cost = 1\n",
      "\n",
      "\n",
      "The optimal cost is :  -3\n"
     ]
    }
   ],
   "source": [
    "# Define problem parameters\n",
    "cost_matrix = [[2, 1, -1, 1], [4, 5, -2, -3], [1, 2, -1, 5]]\n",
    "\n",
    "# Solve the linear sum assignment problem\n",
    "print(\"Solving the linear sum assignment problem\")\n",
    "row_ind, col_ind = sciopt.linear_sum_assignment(cost_matrix=cost_matrix)\n",
    "\n",
    "# Print the solution\n",
    "print(\"\\n\")\n",
    "print(\"Row index : \", row_ind)\n",
    "print(\"Col index : \", col_ind)\n",
    "\n",
    "# Print selected edges and the costs\n",
    "print(\"\\n\")\n",
    "print(\"The selected edges in the optimal assignment and their costs are:\")\n",
    "cost_opt = 0\n",
    "for ind, row in enumerate(row_ind):\n",
    "    col = col_ind[ind]\n",
    "    cost_opt += cost_matrix[row][col]\n",
    "    print(\"Edge (\" + str(row) + \",\" + str(col) + \") , Cost = \" + str(cost_matrix[row][col]))\n",
    "\n",
    "# Print optimal cost\n",
    "print(\"\\n\")\n",
    "print(\"The optimal cost is : \", cost_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Root finding problems - univariate rootfinding\n",
    "\n",
    "```scipy.optimize``` provides a bunch of functions for finding the roots of a **continuous** univariate function $f$. $x$ is a root of $f$ if and only if $f(x) = 0$. We illustrate some of the important ones with an example.\n",
    "\n",
    "Consider the function $f(x) = x^4 - x^2$. The function has 3 roots ${-1,0,1}$. The function is graphed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'$x^4 - x^2$')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def func(x):\n",
    "    return x**4 - x**2\n",
    "\n",
    "step = 0.01\n",
    "max_x = 1.2\n",
    "x = np.arange(-max_x, max_x + step, step)\n",
    "y = func(x)\n",
    "\n",
    "plt.plot(x, y, \"-r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.ylabel(\"$x^4 - x^2$\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important functions in ```scipy.optimize``` for finding the roots of $f$ can be divided into two categories:\n",
    "- **Root finding on an interval**: Requires that an interval $[a,b]$ be specified such that $f(a)f(b) < 0$, i.e. the function has different signs at the end points of the interval. The methods that can be used in this setting are ```scipy.optimize.brentq```, ```scipy.optimize.brenth```, ```scipy.optimize.bisect```, ```scipy.optimize.ridder```.\n",
    "- **Root finding near a point**: Requires a starting point $x_0$. The method that can be used in this setting is ```scipy.optimize.newton```.\n",
    "\n",
    "More information on these methods can be obtained by clicking on each of these functions, starting from the <a href=\"https://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize\" style=\"text-decoration: none;\">documentation page</a> for ```scipy.optimize```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Root finding in an interval\n",
    "Let us first try to search for a root in the interval $[-1.5, 0.5]$ using the different methods, and print some performance metrics related to convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "brentq method results\n",
      "\n",
      "Root detected at x =  -1.0000000000000588\n",
      "Performance parameters:\n",
      "      converged: True\n",
      "           flag: 'converged'\n",
      " function_calls: 68\n",
      "     iterations: 67\n",
      "           root: -1.0000000000000588\n",
      "\n",
      "\n",
      "brenth method results\n",
      "\n",
      "Root detected at x =  -1.0\n",
      "Performance parameters:\n",
      "      converged: True\n",
      "           flag: 'converged'\n",
      " function_calls: 67\n",
      "     iterations: 66\n",
      "           root: -1.0\n",
      "\n",
      "\n",
      "ridder method results\n",
      "\n",
      "Root detected at x =  -1.0000000000009923\n",
      "Performance parameters:\n",
      "      converged: True\n",
      "           flag: 'converged'\n",
      " function_calls: 16\n",
      "     iterations: 7\n",
      "           root: -1.0000000000009923\n",
      "\n",
      "\n",
      "bisect method results\n",
      "\n",
      "Root detected at x =  -1.0\n",
      "Performance parameters:\n",
      "      converged: True\n",
      "           flag: 'converged'\n",
      " function_calls: 4\n",
      "     iterations: 2\n",
      "           root: -1.0\n"
     ]
    }
   ],
   "source": [
    "# Set a, b\n",
    "a = -1.5\n",
    "b = 0.5\n",
    "\n",
    "# Solve using different methods\n",
    "root1, result1 = sciopt.brentq(f=func, a=a, b=b, full_output=True, disp=True)\n",
    "root2, result2 = sciopt.brenth(f=func, a=a, b=b, full_output=True, disp=True)\n",
    "root3, result3 = sciopt.ridder(f=func, a=a, b=b, full_output=True, disp=True)\n",
    "root4, result4 = sciopt.bisect(f=func, a=a, b=b, full_output=True, disp=True)\n",
    "\n",
    "# Print messages\n",
    "print(\"\\n\\nbrentq method results\\n\")\n",
    "print(\"Root detected at x = \", root1)\n",
    "print(\"Performance parameters:\")\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n\\nbrenth method results\\n\")\n",
    "print(\"Root detected at x = \", root2)\n",
    "print(\"Performance parameters:\")\n",
    "print(result2)\n",
    "\n",
    "print(\"\\n\\nridder method results\\n\")\n",
    "print(\"Root detected at x = \", root3)\n",
    "print(\"Performance parameters:\")\n",
    "print(result3)\n",
    "\n",
    "print(\"\\n\\nbisect method results\\n\")\n",
    "print(\"Root detected at x = \", root4)\n",
    "print(\"Performance parameters:\")\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 2\n",
    "Try different values of $[a,b]$ and check the performance comparison as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Root finding near a point\n",
    "Next let us try to search for a root of the same function $f(x) = x^4 - x^2$ near a point, using the Newton algorithm. The Newton algorithm ```scipy.optimize.newton``` can take in optional parameters which are the first and second derivatives of the function. When derivatives are not provided the **secant method** is used. When the first derivative is provided, the algorithm used is called **Newton-Raphson**. When both first and second derivatives are provided, the algorithm used is called **Halley's algorithm**.\n",
    "\n",
    "**Note: It is very important to check the result $x$ from this algorithm, i.e, if $f(x) = 0$, as convergence is only guaranteed when one starts near a zero**.\n",
    "\n",
    "We first code up the function first and second derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_prime(x):\n",
    "    return 4 * (x ** 3) - 2 * x\n",
    "\n",
    "def func_prime2(x):\n",
    "    return 12 * (x ** 2) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the effect of running these different algorithms for finding a root of our function, starting from the point $x_0 = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing the roots :\n",
      "Secant method :  1.7614525405214752e-08\n",
      "Newton-Rapheson method :  1.4586678995097246e-08\n",
      "Halley's method :  5.324162359300112e-09\n"
     ]
    }
   ],
   "source": [
    "# Define starting point\n",
    "x0 = 0.5\n",
    "\n",
    "# Solve using secant method\n",
    "root_secant = sciopt.newton(func=func, x0=x0)\n",
    "\n",
    "# Solve using Newton-Rapheson method\n",
    "root_newton = sciopt.newton(func=func, x0=x0, fprime=func_prime)\n",
    "\n",
    "# Solve using Halley's method\n",
    "root_halley = sciopt.newton(func=func, x0=x0, fprime=func_prime, fprime2=func_prime2)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPrinting the roots :\")\n",
    "print(\"Secant method : \", root_secant)\n",
    "print(\"Newton-Rapheson method : \", root_newton)\n",
    "print(\"Halley's method : \", root_halley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 3\n",
    "Try different values of $x_0$ and check what happens with each root finding method. Do you see something strange for $x_0 = 0.7$? If yes, can you explain it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Root finding problems - multivariate rootfinding\n",
    "\n",
    "We now turn to the much harder problem of finding zeros of functions of the form  $f : \\mathbb{R}^m \\rightarrow \\mathbb{R}^n$. ```scipy.optimize``` provides a single function ```scipy.optimize.root```, through which all the other functions listed in the <a href=\"https://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize\" style=\"text-decoration: none;\">documentation page</a> for multivariate root finding are accessible. All the algorithms require an initial guess (or starting point) $x_0$. The syntax for the function ```scipy.optimize.root``` can be found <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root.html#scipy.optimize.root\" style=\"text-decoration: none;\">here</a>.\n",
    "\n",
    "The important parameters that this function accepts, and about which you should be aware of are:\n",
    "- ```fun```: A function that implements $f$. The function can optionally return the Jacobian as well.\n",
    "- ```x0```: Initial guess.\n",
    "- ```method```: The type of solver to use. Options include ```hybr```, ```krylov```, ```broyden1``` etc.\n",
    "- ```jac```: Either a ```bool```, or a callable function that returns the Jacobian. In this case, it must accept the same arguments as fun.\n",
    "- ```options```: A dictionary with optional arguments for the solver ```method```.\n",
    "\n",
    "**Note:** If ```jac``` is a Boolean and is True, ```fun``` is assumed to return the value of Jacobian along with the objective function. If False, the Jacobian will be estimated numerically. Also one should be aware that many methods do not need the Jacobian implemented; they approximate the Jacobian internally.\n",
    "\n",
    "We will learn to use some of the features of ```scipy.optimize.root``` using an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 1\n",
    "Consider the function $f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ defined as\n",
    "\n",
    "$$\n",
    "f(x,y) = ((x - x_t)^2 - (y - y_t)^2, 2(x - x_t)(y - y_t)),\n",
    "$$\n",
    "\n",
    "for some $(x_t, y_t) \\in \\mathbb{R}^2$.\n",
    "\n",
    "Alternatively you can also think of this function as $f : \\mathbb{C} \\rightarrow \\mathbb{C}$, defined as $f(z) = (z - z_t)^2$, where $z = x + i y$, and $z_t = x_t + i y_t$. Clearly this function has only one root $z = z_t$, i.e. $(x, y) = (x_t, y_t)$.\n",
    "\n",
    "Let us code up the function and its Jacobian. The Jacobian is given by\n",
    "\n",
    "$$\n",
    "J(x,y) = \n",
    "\\begin{bmatrix}\n",
    "2(x - x_t) & 2(y - y_t) \\\\\n",
    "-2(y - y_t) & 2(x - x_t)\n",
    "\\end{bmatrix}\n",
    ".\n",
    "$$\n",
    "\n",
    "Set $x_t = 1, y_t = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define xt, yt\n",
    "xt = 1\n",
    "yt = 1\n",
    "\n",
    "# Define the function\n",
    "def fun(x):\n",
    "    return [(x[0] - xt) ** 2 - (x[1] - yt) ** 2, 2 * (x[0] - xt) * (x[1] - yt)]\n",
    "\n",
    "# Define the Jacobian\n",
    "def jac(x):\n",
    "    return [[2 * (x[0] - xt), 2 * (x[1] - yt)], [-2 * (x[1] - yt), 2 * (x[0] - xt)]]\n",
    "\n",
    "# Define the function that also returns the Jacobian\n",
    "def fun1(x):\n",
    "    return (\n",
    "        [(x[0] - xt) ** 2 - (x[1] - yt) ** 2, 2 * (x[0] - xt) * (x[1] - yt)], \n",
    "        [[2 * (x[0] - xt), 2 * (x[1] - yt)], [-2 * (x[1] - yt), 2 * (x[0] - xt)]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a starting guess of the root $(x_0, y_0) = (0.5, 0.5)$, and lets demonstrate how the Jacobian can be passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 \n",
      "\n",
      "    fjac: array([[ 0.98400183,  0.17815833],\n",
      "       [-0.17815833,  0.98400183]])\n",
      "     fun: array([3.09280704e-17, 1.47994165e-17])\n",
      " message: 'The solution converged.'\n",
      "    nfev: 60\n",
      "    njev: 3\n",
      "     qtf: array([1.05477780e-16, 2.65636348e-17])\n",
      "       r: array([-2.93722421e-08,  2.88725167e-08, -2.92569278e-08])\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.99999999, 1.        ]) \n",
      "\n",
      "Solution : x =  0.9999999942897184 , y =  0.999999998704143 \n",
      "\n",
      "\n",
      "\n",
      "Method 2 \n",
      "\n",
      "    fjac: array([[-1.00000000e+00, -1.26928271e-15],\n",
      "       [ 1.26928271e-15, -1.00000000e+00]])\n",
      "     fun: array([0.0000000e+00, 2.2186713e-31])\n",
      " message: 'The solution converged.'\n",
      "    nfev: 75\n",
      "     qtf: array([-1.12644845e-45, -8.87468518e-31])\n",
      "       r: array([ 9.99999993e-01, -9.99999993e-01,  2.92304139e-15])\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([1., 1.]) \n",
      "\n",
      "Solution : x =  0.9999999999999997 , y =  0.9999999999999997 \n",
      "\n",
      "\n",
      "\n",
      "Method 3 \n",
      "\n",
      "    fjac: array([[ 0.98400183,  0.17815833],\n",
      "       [-0.17815833,  0.98400183]])\n",
      "     fun: array([3.09280704e-17, 1.47994165e-17])\n",
      " message: 'The solution converged.'\n",
      "    nfev: 60\n",
      "    njev: 3\n",
      "     qtf: array([1.05477780e-16, 2.65636348e-17])\n",
      "       r: array([-2.93722421e-08,  2.88725167e-08, -2.92569278e-08])\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.99999999, 1.        ]) \n",
      "\n",
      "Solution : x =  0.9999999942897184 , y =  0.999999998704143 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define starting guess\n",
    "x0 = [0.5, 0.5]\n",
    "\n",
    "# Demonstrate usage using different ways to supply function and Jacobian\n",
    "\n",
    "print(\"Method 1\", \"\\n\")\n",
    "sol = sciopt.root(fun=fun1, x0=x0, jac=True, method='hybr')\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")\n",
    "\n",
    "print(\"Method 2\", \"\\n\")\n",
    "sol = sciopt.root(fun=fun, x0=x0, jac=False, method='hybr')\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")\n",
    "\n",
    "print(\"Method 3\", \"\\n\")\n",
    "sol = sciopt.root(fun=fun, x0=x0, jac=jac, method='hybr')\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 4\n",
    "1. Try different values of the starting guess $(x_0, y_0)$, and see the impact on performance, as measured by the number of function and Jacobian evaluations.\n",
    "2. Repeat the experiment with different values of $(x_t, y_t)$. What happens as you approach $x_t = 0, y_t = 0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 2\n",
    "Consider the following system of nonlinear equations\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "x + \\frac{(x - y)^3}{2} - 1 &= 0 \\\\\n",
    "\\frac{(y - x)^3}{2} + y &= 0 \\;.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We can try to solve this system by trying to find the roots of the function $f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ defined as\n",
    "\n",
    "$$\n",
    "f(x,y) = \\left( x + \\frac{(x - y)^3}{2} - 1, \\frac{(y - x)^3}{2} + y \\right).\n",
    "$$\n",
    "\n",
    "We code up the function, its Jacobian, and solve the problem using a few different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method hybr \n",
      "\n",
      "    fjac: array([[ 0.95527545, -0.29571744],\n",
      "       [ 0.29571744,  0.95527545]])\n",
      "     fun: array([-1.11022302e-16,  2.77555756e-17])\n",
      " message: 'The solution converged.'\n",
      "    nfev: 10\n",
      "    njev: 1\n",
      "     qtf: array([-1.11891287e-11,  5.89928428e-12])\n",
      "       r: array([ 1.51616686, -1.4821053 ,  1.5807719 ])\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.8411639, 0.1588361]) \n",
      "\n",
      "Solution : x =  0.8411639019140096 , y =  0.15883609808599033 \n",
      "\n",
      "\n",
      "\n",
      "Method lm \n",
      "\n",
      "   cov_x: array([[0.58704377, 0.41295623],\n",
      "       [0.41295623, 0.58704377]])\n",
      "    fjac: array([[-1.83633283, -0.38029971],\n",
      "       [ 1.29176924, -1.30516302]])\n",
      "     fun: array([-1.11022302e-16,  2.77555756e-17])\n",
      "    ipvt: array([1, 2], dtype=int32)\n",
      " message: 'The relative error between two consecutive iterates is at most 0.000000'\n",
      "    nfev: 7\n",
      "    njev: 6\n",
      "     qtf: array([-1.85329897e-10,  7.73266306e-11])\n",
      "  status: 2\n",
      " success: True\n",
      "       x: array([0.8411639, 0.1588361]) \n",
      "\n",
      "Solution : x =  0.8411639019140096 , y =  0.15883609808599033 \n",
      "\n",
      "\n",
      "\n",
      "Method broyden1 \n",
      "\n",
      "     fun: array([-2.20142724e-07,  6.78306977e-08])\n",
      " message: 'A solution was found at the specified tolerance.'\n",
      "     nit: 11\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.84116377, 0.15883608]) \n",
      "\n",
      "Solution : x =  0.841163765681265 , y =  0.15883608200670896 \n",
      "\n",
      "\n",
      "\n",
      "Method anderson \n",
      "\n",
      "     fun: array([ 3.39165093e-07, -3.43755319e-07])\n",
      " message: 'A solution was found at the specified tolerance.'\n",
      "     nit: 9\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.84116404, 0.15883595]) \n",
      "\n",
      "Solution : x =  0.841164042089031 , y =  0.15883595332074232 \n",
      "\n",
      "\n",
      "\n",
      "Method krylov \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\cme193\\lib\\site-packages\\scipy\\optimize\\_root.py:209: RuntimeWarning: Method broyden1 does not use the jacobian (jac).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: array([0.19069831, 0.08409976])\n",
      " message: 'The maximum number of iterations allowed has been reached.'\n",
      "     nit: 300\n",
      "  status: 2\n",
      " success: False\n",
      "       x: array([1.        , 0.27479807]) \n",
      "\n",
      "Solution : x =  1.0 , y =  0.2747980741784015 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the function\n",
    "def fun_nonlinear_eq(x):\n",
    "    return [x[0] + 0.5 * ((x[0] - x[1]) ** 3) - 1, 0.5 * ((x[1] - x[0]) ** 3) + x[1]]\n",
    "\n",
    "# Define the Jacobian\n",
    "def jac_nonlinear_eq(x):\n",
    "    return [\n",
    "        [1 + 1.5 * ((x[0] - x[1]) ** 2), -1.5 * ((x[1] - x[0]) ** 2)], \n",
    "        [-1.5 * ((x[0] - x[1]) ** 2), 1 + 1.5 * ((x[1] - x[0]) ** 2)]\n",
    "    ]\n",
    "\n",
    "# Define starting guess\n",
    "x0 = [1, 1]\n",
    "\n",
    "# Solve using method 'hybr'\n",
    "name = 'hybr'\n",
    "print(\"Method \" + name, \"\\n\")\n",
    "sol = sciopt.root(fun=fun_nonlinear_eq, x0=x0, jac=jac_nonlinear_eq, method=name)\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")\n",
    "\n",
    "# Solve using method 'lm'\n",
    "name = 'lm'\n",
    "print(\"Method \" + name, \"\\n\")\n",
    "sol = sciopt.root(fun=fun_nonlinear_eq, x0=x0, jac=jac_nonlinear_eq, method=name)\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")\n",
    "\n",
    "# Methods below do not use Jacobian -- should throw an warning if Jacobian is passed\n",
    "\n",
    "# Solve using method 'broyden1'\n",
    "name = 'broyden1'\n",
    "print(\"Method \" + name, \"\\n\")\n",
    "sol = sciopt.root(fun=fun_nonlinear_eq, x0=x0, jac=jac_nonlinear_eq, method=name)\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")\n",
    "\n",
    "# Solve using method 'anderson'\n",
    "name = 'anderson'\n",
    "print(\"Method \" + name, \"\\n\")\n",
    "sol = sciopt.root(fun=fun_nonlinear_eq, x0=x0, method=name)\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")\n",
    "\n",
    "# Solve using method 'krylov'\n",
    "name = 'krylov'\n",
    "print(\"Method \" + name, \"\\n\")\n",
    "sol = sciopt.root(fun=fun_nonlinear_eq, x0=x0, method=name)\n",
    "print(sol, \"\\n\")\n",
    "print(\"Solution : x = \", sol.x[0], \", y = \", sol.x[1], \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 5\n",
    "1. Increase the maximum number of iterations for the 'krylov' method and see if there is an impact on the solution.\n",
    "2. Try different starting guesses for $(x_0, y_0)$, for e.g. try $(0.8, 0.2)$ for the 'krylov' method. Does it help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Fixed point iterations\n",
    "\n",
    "```scipy.optimize``` provides a special function ```scipy.optimize.fixed_point``` for finding fixed points of functions of the form $f : \\mathbb{R}^m \\rightarrow \\mathbb{R}^m$. $x \\in \\mathbb{R}^m$ is a fixed point of $f$ if and only if $f(x) = x$. The syntax for the function ```scipy.optimize.fixed_point``` can be found <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fixed_point.html#scipy.optimize.fixed_point\" style=\"text-decoration: none;\">here</a>.\n",
    "\n",
    "There are two main algorithms which are supported by this function: ```iteration``` and ```del2```. The default method is ```del2``` which uses Steffensens Method with Aitkens convergence acceleration. The ```iteration``` method simply iterates the function until convergence is detected, without attempting to accelerate the convergence.\n",
    "\n",
    "We demonstrate the usage of this method with a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 1\n",
    "Let us consider the problem of finding a solution to the equation $\\sin (\\alpha x) = \\beta x$, for $\\alpha, \\beta \\in \\mathbb{R}$. The roots of this equation can be expressed as fixed points of the function $f(x) = \\frac{\\sin (\\alpha x)}{\\beta}$.\n",
    "\n",
    "Let us plot the functions $\\sin(\\alpha x)$ and $\\beta x$ below. You can change $\\alpha$ and $\\beta$ and see the changes in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x243cee54710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "alpha = 1\n",
    "beta = 0.5\n",
    "\n",
    "step = 0.01\n",
    "max_x = 5\n",
    "x = np.arange(-max_x, max_x + step, step)\n",
    "y1 = np.sin(alpha * x)\n",
    "y2 = beta * x\n",
    "\n",
    "plt.plot(x, y1, \"-r\", label=\"$\\sin$(\" + str(alpha) + \"x)\")\n",
    "plt.plot(x, y2, \"-b\", label=str(beta) + \"x\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\", fontsize=16)\n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code solves the problem for $\\alpha = 1, \\beta = 1$, with a starting guess $x_0 = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed point detected : x =  0.00012560345075422456\n"
     ]
    }
   ],
   "source": [
    "# Define the function\n",
    "def func_sinx(x, alpha, beta):\n",
    "    return np.sin(alpha * x) / beta\n",
    "\n",
    "# Define alpha, beta\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "# Define initial guess\n",
    "x0 = 0.5\n",
    "\n",
    "# Solve\n",
    "fp = sciopt.fixed_point(func=func_sinx, x0=x0, args=(alpha, beta), method=\"del2\")\n",
    "\n",
    "# Print result\n",
    "print(\"Fixed point detected : x = \", fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 6\n",
    "Experiment with different values of $\\alpha, \\beta, x_0$ in the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Example 2\n",
    "Consider the function $f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$, defined as\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = \\left( \\frac{a_1}{x_1 + b_1}, \\frac{a_2}{x_2 + b_2} \\right),\n",
    "$$\n",
    "\n",
    "for some $a_1, b_1, a_2, b_2 \\in \\mathbb{R}$.\n",
    "\n",
    "The following Python code finds a fixed point of $f$ for $a_1 = 10, b_1 = 3, a_2 = 12, b_2 = 5$, and starting guess $(0,0)$. You can vary these parameters and see the changes in the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed point detected : x1 =  1.4920333011718168 , x2 =  1.3722813232690143\n"
     ]
    }
   ],
   "source": [
    "# Define the function\n",
    "def func_fixed_point(x, a, b):\n",
    "    return np.sqrt(a / (x + b))\n",
    "\n",
    "# Define the parameters\n",
    "a = [10, 12]\n",
    "b = [3, 5]\n",
    "\n",
    "# Define starting guess\n",
    "x0 = [0, 0]\n",
    "\n",
    "# Solve the problem\n",
    "fp = sciopt.fixed_point(func=func_fixed_point, x0=x0, args=(a, b), method=\"del2\")\n",
    "\n",
    "# Print result\n",
    "print(\"Fixed point detected : x1 = \", fp[0], \", x2 = \", fp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Exercise 7\n",
    "1. Formulate the above example as a multivariate root finding problem and solve it.\n",
    "2. Formulate the above example as a scalar root finding problem and solve it.\n",
    "3. Compare the performance of the two strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Local optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cme193]",
   "language": "python",
   "name": "conda-env-cme193-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
