{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME 193 - Lecture 5 - Pandas\n",
    "\n",
    "Before we get started, you may want to make sure that you have the following packages installed in whatever environment you're using: `pandas`\n",
    "\n",
    "```bash\n",
    "conda install pandas\n",
    "```\n",
    "\n",
    "Pandas is a package for working with tabular data.  \n",
    "\n",
    "We'll also cover dictionaries and lambda functions today.\n",
    "\n",
    "At the end of class, we'll have a longer exercise than usual in a supplemental notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a Python library for dealing with data.  The main thing you'll hear people talk about is the DataFrame object (inspired by R), which is designed to hold tabular data.\n",
    "\n",
    "## Difference between a DataFrame and NumPy Array\n",
    "\n",
    "Pandas DataFrames and NumPy arrays both have similarities to Python lists.  \n",
    "* Numpy arrays are designed to contain data of one type (e.g. Int, Float, ...)\n",
    "* DataFrames can contain different types of data (Int, Float, String, ...)\n",
    "    * Usually each column has the same type\n",
    "    \n",
    "    \n",
    "Both arrays and DataFrames are optimized for storage/performance beyond Python lists\n",
    "\n",
    "Pandas is also powerful for working with missing data, working with time series data, for reading and writing your data, for reshaping, grouping, merging your data, ...\n",
    "\n",
    "## Key Features\n",
    "\n",
    "* File I/O - integrations with multiple file formats\n",
    "* Working with missing data (.dropna(), pd.isnull())\n",
    "* Normal table operations: merging and joining, groupby functionality, reshaping via stack, and pivot_tables,\n",
    "* Time series-specific functionality:\n",
    "    * date range generation and frequency conversion, moving window statistics/regressions, date shifting and lagging, etc.\n",
    "* Built in Matplotlib integration\n",
    "\n",
    "## Other Strengths\n",
    "\n",
    "* Strong community, support, and documentation\n",
    "* Size mutability: columns can be inserted and deleted from DataFrame and higher dimensional objects\n",
    "* Powerful, flexible group by functionality to perform split-apply-combine operations on data sets, for both aggregating and transforming data\n",
    "* Make it easy to convert ragged, differently-indexed data in other Python and NumPy data structures into DataFrame objects Intelligent label-based slicing, fancy indexing, and subsetting of large data sets\n",
    "\n",
    "## Python/Pandas vs. R\n",
    "\n",
    "* R is a language dedicated to statistics. Python is a general-purpose language with statistics modules.\n",
    "* R has more statistical analysis features than Python, and specialized syntaxes.\n",
    "\n",
    "However, when it comes to building complex analysis pipelines that mix statistics with e.g. image analysis, text mining, or control of a physical experiment, the richness of Python is an invaluable asset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "[Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) is a link to the documentation for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objects and Basic Creation\n",
    "\n",
    "| Name | Dimensions | Description  |\n",
    "| ------:| -----------:|----------|\n",
    "| ```pd.Series``` | 1 | 1D labeled homogeneously-typed array |\n",
    "| ```pd.DataFrame```  | 2| General 2D labeled, size-mutable tabular structure |\n",
    "| ```pd.Panel``` | 3|  General 3D labeled, also size-mutable array |\n",
    "\n",
    "# Series\n",
    "## What are they?\n",
    "- Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n",
    "- Basic method to create a series: \n",
    "```python \n",
    "s = pd.Series(data, index = index) ```\n",
    "- Data Can be many things:\n",
    "    * A Python Dictionary\n",
    "    * An ndarray (or reg. list)\n",
    "    * A scalar \n",
    "- The passed index is a list of axis labels (which varies on what data is)\n",
    "\n",
    "Think \"Series = Vector + labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_series = pd.Series([1,2,4,8,16,32,64])\n",
    "print(type(first_series))\n",
    "print(first_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s)\n",
    "print('-'*50)\n",
    "print(s.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Data is a dictionary, if index is passed the values in data corresponding to the labels in the index will be pulled out, otherwise an index will be constructed from the sorted keys of the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'a': [0., 0], 'b': {'1':1.}, 'c': 2.}\n",
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Note: Dictionaries\n",
    "\n",
    "We've seen Python lists.  Dictionaries are just another built-in Python data structure.  Dictionaries consist of key-value pairs, and are constructed using \n",
    "```python\n",
    "D = { key : value, ...}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {1 : 5, 2 : 6}\n",
    "# iteration over dictionary\n",
    "for (k,v) in D.items():\n",
    "    print(\"key : %d   value : %d\" % (k, v))\n",
    "    \n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "D = {'a' : 1, 'b' : 2}\n",
    "D['c'] = 3 # another way to set a key-value pair\n",
    "# another way to iterate\n",
    "for k in D:\n",
    "    v = D[k] # access value with key k\n",
    "    print(\"key : %s   value : %d\" % (k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Pandas series...\n",
    "\n",
    "You can create a series from a scalar, but need to specify indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(5, index = ['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index and slice series like you would numpy arrays/python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_string = '\\n' + '-'*50 + '\\n'\n",
    "s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[0], end = end_string)\n",
    "# slicing\n",
    "print(s[:3], end =end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional max - index with booleans\n",
    "print(s[ s > s.mean()], end = end_string)\n",
    "# elementwise function - vectorization\n",
    "print(np.exp(s), end = end_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series are also like dictionaries - you can access values using index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s, end = end_string)\n",
    "print(s['a'], end = end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['e'] = 12 # set element using index label\n",
    "print(s, end = end_string)\n",
    "print('e' in s, end = end_string) # check for index label\n",
    "print(s.get('f', None), end = end_string) # get item with index 'f' - if no such item return None\n",
    "print(s.get('e', None), end = end_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Attributes:\n",
    "\n",
    "- Get the index : \n",
    "```python \n",
    "s.index ``` \n",
    "- Get the values :\n",
    "``` python \n",
    "s.values ``` \n",
    "- Find the shape : \n",
    "``` python \n",
    "s.shape ``` \n",
    "\n",
    "### Series Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,val in s.iteritems():\n",
    "    print(idx,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by index or by value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.sort_index(), end = end_string)\n",
    "print(s.sort_values(), end = end_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find counts of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([0,0,0,1,1,1,2,2,2,2])\n",
    "sct = s.value_counts() # what is the type of sct?\n",
    "print(sct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do just about anything you can do with a numpy array\n",
    "\n",
    "- Series.mean()\n",
    "- Series.median()\n",
    "- Series.mode()\n",
    "- Series.nsmallest(num)\n",
    "- Series.max ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.min(),end = end_string)\n",
    "print(s.max(), end = end_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "- DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object.\n",
    "- You can create a DataFrame from:\n",
    "    - Dict of 1D ndarrays, lists, dicts, or Series\n",
    "    - 2-D numpy array\n",
    "    - A list of dictionaries\n",
    "    - A Series\n",
    "    - Another Dataframe\n",
    "``` python\n",
    "df = pd.DataFrame(data, index = index, columns = columns)\n",
    "```\n",
    "- ```index```/ ``` columns ``` is a list of the row/ column labels. If you pass an index and/ or columns, you are guarenteeing the index and /or column of the df. \n",
    "- If you do not pass anything in, the input will be constructed by \"common sense\" rules\n",
    "\n",
    "[**pandas.DataFrame**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n",
    "\n",
    "# DataFrame Creation From dict of series or dicts\n",
    "- The index of the resulting DataFrame will be the union of the indices of the various Series. If there are any nested dicts, these will be first converted to Series. \n",
    "- If no columns are passed, the columns will be the sorted list of dict keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of series\n",
    "d = {'one': pd.Series([1,2,3], index  = ['a', 'b', 'c']), \n",
    "     'two': pd.Series(list(range(4)), index = ['a','b', 'c', 'd'])}\n",
    "df = pd.DataFrame(d)\n",
    "print(df, end = end_string)\n",
    "\n",
    "d= {'one': {'a': 1, 'b': 2, 'c':3}, \n",
    "     'two': pd.Series(list(range(4)), index = ['a','b', 'c', 'd'])}\n",
    "# Columns are dictionary keys, indices and values obtained from series\n",
    "df = pd.DataFrame(d)\n",
    "# Notice how it fills the column one with NaN for d\n",
    "print(df, end = end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one': pd.Series([1,2,3], index  = ['a', 'b', 'c']), \n",
    "     'two': pd.Series(list(range(4)), index = ['a','b', 'c', 'd'])}\n",
    "\n",
    "print(pd.DataFrame(d, index = ['d', 'b', 'a']), end = end_string)\n",
    "print(pd.DataFrame(d, index = ['d', 'b', 'a'], columns = ['two', 'three']),\n",
    "      end = end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing attributes\n",
    "print(df.index, end = end_string)\n",
    "print(df.columns,end = end_string)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From dict of ndarray / lists\n",
    "- The ndarrays must all be the same length. \n",
    "- If an index is passed, it must clearly also be the same length as the arrays. If no index is passed, the result will be range(n), where n is the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one' : [1., 2., 3., 4.], 'two' : [4., 3., 2., 1.]}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(100):\n",
    "    data += [ {'Column' + str(j):np.random.randint(100) for j in range(5)} ]\n",
    "    # dictionary comprehension!\n",
    "    \n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation from a list of dicts\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head(), end = end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only certain columns\n",
    "df = pd.DataFrame(data, columns = ['Column0', 'Column1'])\n",
    "print(df.head(), end = end_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "- ``` df.index ``` : the row index of df\n",
    "- ``` df.columns ``` : the columns of df\n",
    "- ``` df.shape ``` : the shape of the df\n",
    "- ``` df.values ``` : numpy array of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding and accessing columns \n",
    "d = {'one': pd.Series([1,2,3], index  = ['a', 'b', 'c']), \n",
    "     'two': pd.Series(range(4), index = ['a','b', 'c', 'd'])}\n",
    "df = pd.DataFrame(d)\n",
    "# multiply \n",
    "df['three'] =  df['one']*df['two']\n",
    "# Create a boolean flag\n",
    "df['flag'] = df['one'] > 2\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting column in specified location, with values\n",
    "df.insert(1, 'bar', df['one'][:2])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Columns  \n",
    "three = df.pop('three')\n",
    "print(df.head(), end = end_string)\n",
    "# Propation of values\n",
    "df['foo'] = 'bar'\n",
    "print(df, end = end_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Selection \n",
    "\n",
    "- 4 methods ``` [], ix, iloc, loc ```\n",
    "\n",
    "| Operation  | Syntax       | Result | \n",
    "|----|----------------------| ---------------------------|\n",
    "| Select Column | df[col]   |    Series                      |\n",
    "| Select Row by Label | df.loc[label] | Series  |\n",
    "| Select Row by Integer Location | df.iloc[idx] |      Series                    |\n",
    "| Slice rows | df[5:10]        |                        DataFrame  | \n",
    "| Select rows by boolean | df[mask]   | DataFrame        |\n",
    "\n",
    "- Note all the operations below are valid on series as well restricted to one dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest form Of Indexing: []\n",
    "- Series: selecting a label: s[label] \n",
    "- DataFrame: selection single or multiple columns: \n",
    "``` python \n",
    "df['col'] or df[['col1', 'col2']] ``` \n",
    "- DataFrame: slicing the rows:\n",
    "``` python\n",
    "df['rowlabel1': 'rowlabel2'] ``` \n",
    "or \n",
    "``` python \n",
    "df[boolean_mask] ``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a data frame\n",
    "pd.options.display.max_rows = 4\n",
    "dates = pd.date_range('1/1/2000', periods=8)\n",
    "df = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C','D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column  'A\n",
    "df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple column \n",
    "df[['A', 'B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice by rows\n",
    "df['2000-01-01': '2000-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean mask \n",
    "df[df['A'] > df['B']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You can also access a column by df.colname\n",
    "df.A\n",
    "# Assign via []\n",
    "df['A'] = df['B'].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting by label .loc\n",
    "\n",
    "- is primarily label based, but may also be used with a boolean array.\n",
    "- .loc will raise KeyError when the items are not found\n",
    "- Allowed inputs:\n",
    "    1. A single label \n",
    "    2. A list of labels\n",
    "    3. A boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selection by label .loc\n",
    "df.loc['2000-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing all greater than a date \n",
    "df.loc['2000-01-01':, ['A', 'B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for which value is greater than 0 on certain day, get all rows\n",
    "df.loc[:, df.loc['2000-01-01'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting by position \n",
    "\n",
    "- The .iloc attribute is the primary access method. The following are valid input:\n",
    "    - An integer\n",
    "    - A list of integers\n",
    "    - A slice \n",
    "    - A boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(6,4), \n",
    "                   index=list(range(0,12,2)), columns=list(range(0,12,3)))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows 0-2\n",
    "df1.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  rows 1:4  and columns 2 : 4\n",
    "df1.iloc[1:5, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select via integer list\n",
    "df1.iloc[[1,3,5], [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting via integer mask \n",
    "boolean_mask = df1.iloc[:, 1] > 0.0\n",
    "df1.iloc[boolean_mask.values,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging DataFrames\n",
    "\n",
    "- Pandas has full-featured, very high performance, in memory join operations that are very similar to SQL and R \n",
    "\n",
    "- The documentation is https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n",
    "\n",
    "- Pandas provides a single function, merge, as the entry point for all standard database join operations between DataFrame objects: \n",
    "``` python\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "left_index=False, right_index=False, sort=True) ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of merge\n",
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [4, 2]})\n",
    "right = pd.DataFrame({'key': ['bar', 'zoo'], 'rval': [4, 5]})\n",
    "\n",
    "print(\"left: \",left,\"right: \",right, sep=end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left, right)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left, right, how=\"outer\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left, right, how=\"left\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left, right, how=\"right\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Application\n",
    " - Row or Column-wise Function Application: Applies function along input axis of DataFrame\n",
    "```python \n",
    "df.apply(func, axis = 0) ``` \n",
    " - Elementwise: apply the function to every element in the df \n",
    " ```python \n",
    "df.applymap(func) ``` \n",
    "\n",
    "- Note, ``` applymap ``` is equivalent to the ``` map ``` function on lists. \n",
    "- Note, ``` Series ``` objects support ``` .map ``` instead of ``` applymap ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLY EXAMPLES\n",
    "df1 = pd.DataFrame(np.random.randn(6,4), index=list(range(0,12,2)), columns=list('abcd'))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to each column\n",
    "df1.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to each row\n",
    "df1.apply(np.mean, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: lambda functions\n",
    "\n",
    "lambda functions allow you to specify a function without giving it a separate declaration.  For example, the function \n",
    "```python\n",
    "lambda x: (x - x.mean())/x.std()\n",
    "```\n",
    "is equivalent to the function\n",
    "```python\n",
    "def normalize(x):\n",
    "    return (x - x.mean())/x.std()\n",
    "```\n",
    "You'll often see lambda functions used in list comprehensions, or in methods (like `map()`, `apply()`, or `applymap()`) that take a function as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use lambda functions  to normalize columns\n",
    "df1 = df1.apply(lambda x: (x - x.mean())/ x.std(), axis = 0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLY EXAMPLES CONT\n",
    "# Create DF with 1000 rows and 3 columns filled with random entries\n",
    "tsdf = pd.DataFrame(np.random.randn(1000, 3), columns=['A', 'B', 'C'],\n",
    "                    index=pd.date_range('1/1/2000', periods=1000))\n",
    "\n",
    "tsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can get trickier, say I wanted to find where the maximum dates occured for each column of the df:\n",
    "tsdf.apply(lambda x: x.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLYMAP EXAMPLES\n",
    "tmp = tsdf.applymap(lambda x: x - 1)\n",
    "print(tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Functions\n",
    "\n",
    "- There are loads of input output features. The highlights most useful to you are likely:\n",
    "    - ``` pd.read_csv ``` / ``` pd.to_csv ``` \n",
    "    - ``` pd.read_excel ``` / ``` pd.to_excel ```\n",
    "    - ``` pd.read_sql ``` / ``` pd.to_sql ```\n",
    "    - ``` pd.read_pickle ``` / ``` pd.to_pickle ```\n",
    "Documentation:\n",
    "\n",
    "* [Pandas Import-Output Functions](https://pandas.pydata.org/pandas-docs/stable/io.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from CSV\n",
    "Here are the first several lines of `iris.csv`:\n",
    "\n",
    "```\n",
    "sepal_length,sepal_width,petal_length,petal_width,name\n",
    "5.1,3.5,1.4,0.2,setosa\n",
    "4.9,3.0,1.4,0.2,setosa\n",
    "4.7,3.2,1.3,0.2,setosa\n",
    "4.6,3.1,1.5,0.2,setosa\n",
    "5.0,3.6,1.4,0.2,setosa\n",
    "5.4,3.9,1.7,0.4,setosa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Can use df.info to find out information about the df \n",
    "data = pd.read_csv('./data/iris.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe and summarize the dataframe\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The split/apply combo (groupyby)\n",
    "- pandas objects can be split on any of their axes. The abstract definition of grouping is to provide a mapping of labels to group names:\n",
    "- Syntax:  \n",
    "    - ``` groups = df.groupby(key) ```\n",
    "    - ``` groups = df.groupby(key, axis = 1) ```\n",
    "    - ``` groups = df.groupby([key1, key2], axis = 1) ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A picture\n",
    "\n",
    "- The group by concept is that we want to apply the same function on subsets of the dataframe, based on some key we use to split the DataFrame into subsets\n",
    "- This idea is referred to as the \"split-apply-combine\" operation:\n",
    "    - Split the data into groups based on some criteria\n",
    "    - Apply a function to each group independently\n",
    "    - Combine the results \n",
    "\n",
    "![image](./img/splitApplyCombine.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key':['A','B','C','A','B','C','A','B','C'],\n",
    "                   'data': [0, 5, 10, 5, 10, 15, 10, 15, 20]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_key = df.groupby('key')\n",
    "\n",
    "sums = groupby_key.aggregate(np.sum)\n",
    "sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting data\n",
    "\n",
    "- The plot method on Series and DataFrame is just a wrapper on matplotlib plt.plot()\n",
    "- Many available plots:\n",
    "    - ‘bar’ or ‘barh’ for bar plots\n",
    "    - ‘hist’ for histogram\n",
    "    - ‘box’ for boxplot\n",
    "    - ‘kde’ or 'density' for density plots • ‘area’ for area plots\n",
    "    - ‘scatter’ for scatter plots\n",
    "    - ‘hexbin’ for hexagonal bin plots • ‘pie’ for pie plots\n",
    "    \n",
    "- There are several more complex plotting functions in pandas.tools.plotting that take a Series or DataFrame as an argument. These include:\n",
    "    - Scatter matrices\n",
    "    - Andrews Curves\n",
    "    - Autocorrelation\n",
    "    - Bootstrap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick example - Random walks\n",
    "df = pd.DataFrame(np.random.randn(1000, 4), index =pd.date_range('1/1/2000', periods=1000), columns=list('ABCD'))\n",
    "df = df.cumsum()\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.iloc[5].plot(kind = 'bar')\n",
    "plt.axhline(0, color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/iris.csv')\n",
    "ax = data.groupby('name') \\\n",
    "         .get_group('setosa') \\\n",
    "         .boxplot(column=[\"sepal_length\",\"sepal_width\"], return_type='axes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Work through the supplement notebook, posted online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6-cme193)",
   "language": "python",
   "name": "cme193"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
